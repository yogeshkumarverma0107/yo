{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJLUmDbsfkwh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "KAGGLE-OPTIMIZED MULTI-CLASS CLASSIFICATION PIPELINE\n",
        "================================================================================\n",
        "A fast, competition-ready ML pipeline optimized for Kaggle environments:\n",
        "- Uses pre-installed libraries only (no pip install needed)\n",
        "- Executes in 2-3 minutes\n",
        "- Automatic format matching with sample submission\n",
        "- Production-grade accuracy with minimal configuration\n",
        "================================================================================\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n",
        "                              ExtraTreesClassifier, VotingClassifier)\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import (roc_auc_score, log_loss, classification_report,\n",
        "                            accuracy_score, f1_score)\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Import XGBoost (pre-installed on Kaggle)\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except ImportError:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "\n",
        "# Import LightGBM (pre-installed on Kaggle)\n",
        "try:\n",
        "    from lightgbm import LGBMClassifier\n",
        "    LIGHTGBM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    LIGHTGBM_AVAILABLE = False\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 1. USER CONFIGURATION - MODIFY THIS SECTION ONLY\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# 1. USER CONFIGURATION - MODIFY THIS SECTION ONLY\n",
        "# ============================================================================\n",
        "\n",
        "CONFIG = {\n",
        "    # File paths (Kaggle default paths)\n",
        "    'train_path': \"/kaggle/input/mle-ese-mock/train (5).csv\",\n",
        "    'test_path': \"/kaggle/input/mle-ese-mock/test (4).csv\",\n",
        "    'sample_submission_path': \"/kaggle/input/mle-ese-mock/sample_submission.csv\",\n",
        "    'output_file': \"submission.csv\",\n",
        "\n",
        "    # Column configuration\n",
        "    'target_col': \"quality_grade\",  # Can be string or list for multi-target\n",
        "    'id_col': \"id\",\n",
        "\n",
        "    # Competition type\n",
        "    'submission_type': 'probabilities',  # 'probabilities' or 'classes'\n",
        "    'submission_column_prefix': 'Status_',  # Prefix for output columns (e.g., 'Status_')\n",
        "\n",
        "    # Model configuration (optimized for speed and accuracy)\n",
        "    'model_type': 'lightgbm',  # Options: 'lightgbm', 'xgboost', 'random_forest', 'fast_ensemble'\n",
        "    'n_estimators': 500,  # Reduced for speed (500 is sweet spot for 2-3 min)\n",
        "    'use_class_weight': True,\n",
        "\n",
        "    # Fast ensemble (combines top 2 models quickly)\n",
        "    'fast_ensemble_models': ['lightgbm', 'xgboost'],  # Only 2-3 models for speed\n",
        "\n",
        "    # Processing options (optimized for speed)\n",
        "    'do_plotting': False,  # Disable plots to save time\n",
        "    'do_outlier_cap': False,  # Skip outlier capping for speed\n",
        "    'do_hyperparam_tuning': False,  # Disable tuning for speed (use optimized defaults)\n",
        "\n",
        "    # Advanced options\n",
        "    'validation_size': 0.2,\n",
        "    'random_state': 42,\n",
        "    'verbose': True,  # Show progress\n",
        "}\n",
        "\n",
        "RANDOM_STATE = CONFIG['random_state']\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 2. HELPER FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def print_section(title):\n",
        "    \"\"\"Print a formatted section header\"\"\"\n",
        "    if CONFIG.get('verbose', True):\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(title.upper())\n",
        "        print(\"=\"*80)\n",
        "\n",
        "def print_subsection(title):\n",
        "    \"\"\"Print a formatted subsection header\"\"\"\n",
        "    if CONFIG.get('verbose', True):\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(title)\n",
        "        print(\"-\"*80)\n",
        "\n",
        "def detect_feature_types(df, exclude_cols=None):\n",
        "    \"\"\"Automatically detect categorical and numerical columns\"\"\"\n",
        "    if exclude_cols is None:\n",
        "        exclude_cols = []\n",
        "\n",
        "    df = df.drop(columns=exclude_cols, errors='ignore')\n",
        "\n",
        "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    num_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "    # Additional check: if numerical column has few unique values, treat as categorical\n",
        "    for col in num_cols.copy():\n",
        "        if df[col].nunique() < 10 and df[col].nunique() < len(df) * 0.05:\n",
        "            print(f\"  â„¹ '{col}' has few unique values ({df[col].nunique()}), treating as categorical\")\n",
        "            cat_cols.append(col)\n",
        "            num_cols.remove(col)\n",
        "\n",
        "    return cat_cols, num_cols\n",
        "\n",
        "def safe_roc_auc(y_true, y_pred_proba, multi_class='ovr'):\n",
        "    \"\"\"Safely compute ROC AUC with error handling\"\"\"\n",
        "    try:\n",
        "        if len(np.unique(y_true)) == 2:\n",
        "            return roc_auc_score(y_true, y_pred_proba[:, 1])\n",
        "        else:\n",
        "            return roc_auc_score(y_true, y_pred_proba,\n",
        "                               multi_class=multi_class, average='macro')\n",
        "    except Exception as e:\n",
        "        print(f\"  âš  Could not compute ROC AUC: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_model(model_type, n_estimators, use_class_weight, random_state):\n",
        "    \"\"\"\n",
        "    Get optimized model with speed-accuracy balance\n",
        "    \"\"\"\n",
        "    class_weight = 'balanced' if use_class_weight else None\n",
        "\n",
        "    if model_type == 'lightgbm':\n",
        "        if not LIGHTGBM_AVAILABLE:\n",
        "            print(\"âš  LightGBM not available, using Random Forest\")\n",
        "            return get_model('random_forest', n_estimators, use_class_weight, random_state)\n",
        "        return LGBMClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            random_state=random_state,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=7,\n",
        "            num_leaves=50,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            n_jobs=-1,\n",
        "            verbose=-1,\n",
        "            class_weight=class_weight,\n",
        "            min_child_samples=20\n",
        "        )\n",
        "\n",
        "    elif model_type == 'xgboost':\n",
        "        if not XGBOOST_AVAILABLE:\n",
        "            print(\"âš  XGBoost not available, using Random Forest\")\n",
        "            return get_model('random_forest', n_estimators, use_class_weight, random_state)\n",
        "        return XGBClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            random_state=random_state,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=6,\n",
        "            min_child_weight=1,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            n_jobs=-1,\n",
        "            eval_metric='logloss',\n",
        "            tree_method='hist',  # Faster training\n",
        "            verbosity=0\n",
        "        )\n",
        "\n",
        "    elif model_type == 'random_forest':\n",
        "        return RandomForestClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            random_state=random_state,\n",
        "            class_weight=class_weight,\n",
        "            n_jobs=-1,\n",
        "            max_depth=15,\n",
        "            min_samples_split=10,\n",
        "            min_samples_leaf=4,\n",
        "            max_features='sqrt'\n",
        "        )\n",
        "\n",
        "    elif model_type == 'extra_trees':\n",
        "        return ExtraTreesClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            random_state=random_state,\n",
        "            class_weight=class_weight,\n",
        "            n_jobs=-1,\n",
        "            max_depth=15,\n",
        "            min_samples_split=10\n",
        "        )\n",
        "\n",
        "    elif model_type == 'gradient_boosting':\n",
        "        return GradientBoostingClassifier(\n",
        "            n_estimators=min(n_estimators, 300),  # GB is slower, limit trees\n",
        "            random_state=random_state,\n",
        "            max_depth=5,\n",
        "            learning_rate=0.1,\n",
        "            subsample=0.8\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
        "\n",
        "\n",
        "def get_fast_ensemble(ensemble_models, n_estimators, use_class_weight, random_state):\n",
        "    \"\"\"\n",
        "    Create fast voting ensemble (2-3 models max for speed)\n",
        "    \"\"\"\n",
        "    print(f\"\\nâœ“ Building Fast Ensemble: {ensemble_models}\")\n",
        "\n",
        "    estimators = []\n",
        "    for model_name in ensemble_models[:3]:  # Limit to 3 models max\n",
        "        model = get_model(model_name, n_estimators, use_class_weight, random_state)\n",
        "        estimators.append((model_name, model))\n",
        "        print(f\"  + {model_name}\")\n",
        "\n",
        "    return VotingClassifier(\n",
        "        estimators=estimators,\n",
        "        voting='soft',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \"\"\"Plot distribution of target variable(s)\"\"\"\n",
        "    n_targets = len(target_cols) if isinstance(target_cols, list) else 1\n",
        "    target_cols = [target_cols] if isinstance(target_cols, str) else target_cols\n",
        "\n",
        "    fig, axes = plt.subplots(1, n_targets, figsize=(figsize_per_plot*n_targets, 5))\n",
        "    if n_targets == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for idx, target_col in enumerate(target_cols):\n",
        "        counts = data[target_col].value_counts().sort_index()\n",
        "        axes[idx].bar(range(len(counts)), counts.values)\n",
        "        axes[idx].set_title(f\"Distribution: '{target_col}'\")\n",
        "        axes[idx].set_xlabel(\"Class\")\n",
        "        axes[idx].set_ylabel(\"Count\")\n",
        "        axes[idx].set_xticks(range(len(counts)))\n",
        "        axes[idx].set_xticklabels(counts.index, rotation=45, ha='right')\n",
        "\n",
        "        # Add count labels on bars\n",
        "        for i, v in enumerate(counts.values):\n",
        "            axes[idx].text(i, v, str(v), ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 3. DATA LOADING AND INITIAL INSPECTION\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# 3. DATA LOADING AND INITIAL INSPECTION\n",
        "# ============================================================================\n",
        "\n",
        "print_section(\"DATA LOADING\")\n",
        "\n",
        "# Load data\n",
        "train_data = pd.read_csv(CONFIG['train_path'])\n",
        "test_data = pd.read_csv(CONFIG['test_path'])\n",
        "\n",
        "print(f\"\\nâœ“ Data loaded: Train {train_data.shape}, Test {test_data.shape}\")\n",
        "\n",
        "# Load sample submission\n",
        "sample_submission = None\n",
        "if CONFIG.get('sample_submission_path'):\n",
        "    try:\n",
        "        sample_submission = pd.read_csv(CONFIG['sample_submission_path'])\n",
        "        print(f\"âœ“ Sample submission: {sample_submission.shape}\")\n",
        "        if CONFIG.get('verbose'):\n",
        "            print(f\"  Columns: {list(sample_submission.columns)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš  Could not load sample submission: {e}\")\n",
        "\n",
        "# Save test IDs\n",
        "test_ids = test_data[CONFIG['id_col']].copy() if CONFIG['id_col'] in test_data.columns else None\n",
        "\n",
        "# Drop ID columns\n",
        "if CONFIG['id_col'] in train_data.columns:\n",
        "    train_data = train_data.drop(columns=[CONFIG['id_col']])\n",
        "if CONFIG['id_col'] in test_data.columns:\n",
        "    test_data = test_data.drop(columns=[CONFIG['id_col']])\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 4. TARGET CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "print_section(\"TARGET CONFIGURATION\")\n",
        "\n",
        "# Normalize target_col to list\n",
        "if isinstance(CONFIG['target_col'], str):\n",
        "    target_cols = [CONFIG['target_col']]\n",
        "    is_multi_target = False\n",
        "    print(f\"\\nâœ“ Single target: '{CONFIG['target_col']}'\")\n",
        "elif isinstance(CONFIG['target_col'], list):\n",
        "    target_cols = CONFIG['target_col']\n",
        "    is_multi_target = True\n",
        "    print(f\"\\nâœ“ Multi-target: {len(target_cols)} targets\")\n",
        "else:\n",
        "    raise ValueError(\"TARGET_COL must be string or list\")\n",
        "\n",
        "# Verify targets exist\n",
        "missing_targets = [col for col in target_cols if col not in train_data.columns]\n",
        "if missing_targets:\n",
        "    raise ValueError(f\"Target columns not found: {missing_targets}\")\n",
        "\n",
        "# Analyze targets\n",
        "target_info = {}\n",
        "for target_col in target_cols:\n",
        "    unique_classes = sorted(train_data[target_col].dropna().unique())\n",
        "    n_classes = len(unique_classes)\n",
        "\n",
        "    if CONFIG.get('verbose'):\n",
        "        print(f\"\\n{target_col}: {n_classes} classes\")\n",
        "        value_counts = train_data[target_col].value_counts()\n",
        "        min_pct = (value_counts.min() / len(train_data)) * 100\n",
        "        if min_pct < 5:\n",
        "            print(f\"  âš  Imbalanced! Min class: {min_pct:.1f}%\")\n",
        "\n",
        "    target_info[target_col] = {\n",
        "        'n_classes': n_classes,\n",
        "        'classes': unique_classes\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 5. DATA CLEANING\n",
        "# ============================================================================\n",
        "\n",
        "print_section(\"DATA CLEANING\")\n",
        "\n",
        "# Remove duplicates\n",
        "train_dups = train_data.duplicated().sum()\n",
        "if train_dups > 0:\n",
        "    print(f\"âœ“ Removing {train_dups} duplicate rows\")\n",
        "    train_data = train_data.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# Missing values analysis\n",
        "print_subsection(\"Missing Values Analysis\")\n",
        "\n",
        "train_missing = train_data.isnull().sum()\n",
        "test_missing = test_data.isnull().sum()\n",
        "\n",
        "print(\"\\nTrain missing values:\")\n",
        "if train_missing.sum() == 0:\n",
        "    print(\"  âœ“ No missing values\")\n",
        "else:\n",
        "    missing_cols = train_missing[train_missing > 0]\n",
        "    for col, count in missing_cols.items():\n",
        "        pct = (count / len(train_data)) * 100\n",
        "        print(f\"  {col}: {count} ({pct:.2f}%)\")\n",
        "\n",
        "print(\"\\nTest missing values:\")\n",
        "if test_missing.sum() == 0:\n",
        "    print(\"  âœ“ No missing values\")\n",
        "else:\n",
        "    missing_cols = test_missing[test_missing > 0]\n",
        "    for col, count in missing_cols.items():\n",
        "        pct = (count / len(test_data)) * 100\n",
        "        print(f\"  {col}: {count} ({pct:.2f}%)\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 6. FEATURE EXTRACTION AND SEPARATION\n",
        "# ============================================================================\n",
        "\n",
        "print_section(\"FEATURE EXTRACTION\")\n",
        "\n",
        "# Separate features and targets\n",
        "X = train_data.drop(columns=target_cols)\n",
        "y = train_data[target_cols]\n",
        "\n",
        "# Handle missing targets\n",
        "total_nan = y.isnull().any(axis=1).sum()\n",
        "if total_nan > 0:\n",
        "    print(f\"\\nâš  Removing {total_nan} rows with missing target values\")\n",
        "    valid_idx = ~y.isnull().any(axis=1)\n",
        "    X = X[valid_idx].reset_index(drop=True)\n",
        "    y = y[valid_idx].reset_index(drop=True)\n",
        "\n",
        "# Convert to Series for single target\n",
        "if not is_multi_target:\n",
        "    y = y.iloc[:, 0]\n",
        "\n",
        "# Detect feature types\n",
        "cat_cols, num_cols = detect_feature_types(X)\n",
        "\n",
        "print(f\"\\nâœ“ Feature summary:\")\n",
        "print(f\"  Total features: {X.shape[1]}\")\n",
        "print(f\"  Categorical: {len(cat_cols)}\")\n",
        "print(f\"  Numerical: {len(num_cols)}\")\n",
        "\n",
        "if cat_cols:\n",
        "    print(f\"\\n  Categorical columns: {cat_cols}\")\n",
        "if num_cols:\n",
        "    print(f\"\\n  Numerical columns: {num_cols}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 7. EXPLORATORY DATA ANALYSIS (Optional)\n",
        "# ============================================================================\n",
        "\n",
        "if CONFIG['do_plotting']:\n",
        "    print_section(\"EXPLORATORY DATA ANALYSIS\")\n",
        "\n",
        "    # Numerical features - distributions\n",
        "    if len(num_cols) > 0:\n",
        "        print(\"\\nâœ“ Plotting numerical feature distributions...\")\n",
        "        n_num = min(len(num_cols), 12)  # Limit to 12 plots\n",
        "        ncols = 3\n",
        "        nrows = (n_num + ncols - 1) // ncols\n",
        "\n",
        "        fig, axes = plt.subplots(nrows, ncols, figsize=(15, 4*nrows))\n",
        "        axes = axes.flatten() if n_num > 1 else [axes]\n",
        "\n",
        "        for i, col in enumerate(num_cols[:n_num]):\n",
        "            sns.histplot(X[col].dropna(), kde=True, ax=axes[i])\n",
        "            axes[i].set_title(col, fontsize=10)\n",
        "\n",
        "        for i in range(n_num, len(axes)):\n",
        "            axes[i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Categorical features - top categories\n",
        "    if len(cat_cols) > 0:\n",
        "        print(\"\\nâœ“ Plotting categorical feature distributions...\")\n",
        "        for col in cat_cols[:5]:  # Limit to 5\n",
        "            plt.figure(figsize=(10, 4))\n",
        "            top_cats = X[col].value_counts().head(15)\n",
        "            sns.barplot(x=top_cats.values, y=top_cats.index)\n",
        "            plt.title(f\"Top Categories: {col}\")\n",
        "            plt.xlabel(\"Count\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 8. PREPROCESSING PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "print_section(\"DATA PREPROCESSING\")\n",
        "\n",
        "# Imputation\n",
        "print(\"\\nâœ“ Setting up imputation...\")\n",
        "if num_cols:\n",
        "    num_imputer = SimpleImputer(strategy='median')\n",
        "    X[num_cols] = num_imputer.fit_transform(X[num_cols])\n",
        "    test_data[num_cols] = num_imputer.transform(test_data[num_cols])\n",
        "    print(\"  - Numerical: median imputation\")\n",
        "\n",
        "if cat_cols:\n",
        "    cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "    X[cat_cols] = cat_imputer.fit_transform(X[cat_cols])\n",
        "    test_data[cat_cols] = cat_imputer.transform(test_data[cat_cols])\n",
        "    print(\"  - Categorical: most frequent imputation\")\n",
        "\n",
        "# Outlier capping (optional)\n",
        "if CONFIG['do_outlier_cap'] and num_cols:\n",
        "    print(\"\\nâœ“ Capping outliers (IQR method)...\")\n",
        "    for col in num_cols:\n",
        "        q1 = X[col].quantile(0.25)\n",
        "        q3 = X[col].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower = q1 - 1.5 * iqr\n",
        "        upper = q3 + 1.5 * iqr\n",
        "\n",
        "        X[col] = X[col].clip(lower=lower, upper=upper)\n",
        "        test_data[col] = test_data[col].clip(lower=lower, upper=upper)\n",
        "\n",
        "# Create preprocessing pipeline\n",
        "print(\"\\nâœ“ Building preprocessing pipeline...\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
        "        ('num', StandardScaler(), num_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 6. TRAIN/VALIDATION SPLIT & TRANSFORMATION\n",
        "# ============================================================================\n",
        "\n",
        "print_section(\"TRAIN/VALIDATION SPLIT\")\n",
        "\n",
        "stratify_param = y if not is_multi_target else None\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=CONFIG['validation_size'],\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=stratify_param\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ“ Train: {X_train.shape[0]}, Val: {X_val.shape[0]}\")\n",
        "\n",
        "# Transform features\n",
        "print(\"âœ“ Transforming features...\")\n",
        "X_train_pre = preprocessor.fit_transform(X_train)\n",
        "X_val_pre = preprocessor.transform(X_val)\n",
        "test_data_pre = preprocessor.transform(test_data)\n",
        "\n",
        "print(f\"  Shape: {X_train_pre.shape[1]} features after encoding\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 7. LABEL ENCODING\n",
        "# ============================================================================\n",
        "\n",
        "print_section(\"ENCODING TARGETS\")\n",
        "\n",
        "if not is_multi_target:\n",
        "    le = LabelEncoder()\n",
        "    y_train_enc = le.fit_transform(y_train)\n",
        "    y_val_enc = le.transform(y_val)\n",
        "    print(f\"\\nâœ“ Encoded {len(le.classes_)} classes\")\n",
        "else:\n",
        "    label_encoders = {}\n",
        "    y_train_enc = pd.DataFrame(index=y_train.index)\n",
        "    y_val_enc = pd.DataFrame(index=y_val.index)\n",
        "\n",
        "    for target_col in target_cols:\n",
        "        le_temp = LabelEncoder()\n",
        "        y_train_enc[target_col] = le_temp.fit_transform(y_train[target_col])\n",
        "        y_val_enc[target_col] = le_temp.transform(y_val[target_col])\n",
        "        label_encoders[target_col] = le_temp\n",
        "\n",
        "    y_train_enc = y_train_enc.values\n",
        "    y_val_enc = y_val_enc.values\n",
        "    print(f\"\\nâœ“ Encoded {len(target_cols)} targets\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 8. MODEL TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "print_section(\"MODEL TRAINING\")\n",
        "\n",
        "# Select and create model\n",
        "if CONFIG['model_type'] == 'fast_ensemble':\n",
        "    base_model = get_fast_ensemble(\n",
        "        ensemble_models=CONFIG.get('fast_ensemble_models', ['lightgbm', 'xgboost']),\n",
        "        n_estimators=CONFIG['n_estimators'],\n",
        "        use_class_weight=CONFIG['use_class_weight'],\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "else:\n",
        "    print(f\"\\nâœ“ Model: {CONFIG['model_type'].upper()}\")\n",
        "    base_model = get_model(\n",
        "        model_type=CONFIG['model_type'],\n",
        "        n_estimators=CONFIG['n_estimators'],\n",
        "        use_class_weight=CONFIG['use_class_weight'],\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "# Wrap for multi-target if needed\n",
        "if is_multi_target:\n",
        "    model = MultiOutputClassifier(base_model, n_jobs=-1)\n",
        "else:\n",
        "    model = base_model\n",
        "\n",
        "# Train\n",
        "print(\"\\nâ³ Training...\")\n",
        "train_start = time.time()\n",
        "model.fit(X_train_pre, y_train_enc)\n",
        "train_time = time.time() - train_start\n",
        "print(f\"âœ“ Training completed in {train_time:.1f}s\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 9. MODEL EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "print_section(\"EVALUATION\")\n",
        "\n",
        "# Make predictions\n",
        "y_val_pred = model.predict(X_val_pre)\n",
        "\n",
        "if is_multi_target:\n",
        "    print(\"\\nðŸ“Š Multi-Target Metrics:\")\n",
        "    for idx, target_col in enumerate(target_cols):\n",
        "        acc = accuracy_score(y_val_enc[:, idx], y_val_pred[:, idx])\n",
        "        print(f\"  {target_col}: Accuracy={acc:.4f}\")\n",
        "else:\n",
        "    # Get probabilities\n",
        "    try:\n",
        "        y_val_proba = model.predict_proba(X_val_pre)\n",
        "\n",
        "        # Calculate metrics\n",
        "        loss_val = log_loss(y_val_enc, y_val_proba)\n",
        "        acc_val = accuracy_score(y_val_enc, y_val_pred)\n",
        "\n",
        "        print(f\"\\nðŸ“Š Validation Metrics:\")\n",
        "        print(f\"  Log Loss: {loss_val:.4f}\")\n",
        "        print(f\"  Accuracy: {acc_val:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâš  Error: {e}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 13. HYPERPARAMETER TUNING (Optional)\n",
        "# ============================================================================\n",
        "\n",
        "tuned_model = None\n",
        "if CONFIG['do_hyperparam_tuning']:\n",
        "    print_section(\"HYPERPARAMETER TUNING\")\n",
        "\n",
        "    print(\"\\nâ³ Starting RandomizedSearchCV...\")\n",
        "\n",
        "    # Define parameter distributions based on model type\n",
        "    model_type_for_tuning = CONFIG['model_type']\n",
        "    if model_type_for_tuning in ['voting_ensemble', 'stacking_ensemble']:\n",
        "        print(\"  â„¹ Skipping hyperparameter tuning for ensemble models (using base parameters)\")\n",
        "        tuned_model = None\n",
        "    else:\n",
        "        param_prefix = \"estimator__\" if is_multi_target else \"\"\n",
        "\n",
        "        if model_type_for_tuning == 'xgboost' and XGBOOST_AVAILABLE:\n",
        "            param_dist = {\n",
        "                f\"{param_prefix}n_estimators\": [500, 800, 1000, 1500],\n",
        "                f\"{param_prefix}max_depth\": [4, 6, 8, 10],\n",
        "                f\"{param_prefix}learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
        "                f\"{param_prefix}min_child_weight\": [1, 3, 5],\n",
        "                f\"{param_prefix}subsample\": [0.6, 0.8, 1.0],\n",
        "                f\"{param_prefix}colsample_bytree\": [0.6, 0.8, 1.0],\n",
        "            }\n",
        "        elif model_type_for_tuning == 'lightgbm' and LIGHTGBM_AVAILABLE:\n",
        "            param_dist = {\n",
        "                f\"{param_prefix}n_estimators\": [500, 800, 1000, 1500],\n",
        "                f\"{param_prefix}max_depth\": [4, 6, 8, 10],\n",
        "                f\"{param_prefix}learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
        "                f\"{param_prefix}num_leaves\": [31, 50, 70, 100],\n",
        "                f\"{param_prefix}subsample\": [0.6, 0.8, 1.0],\n",
        "                f\"{param_prefix}colsample_bytree\": [0.6, 0.8, 1.0],\n",
        "            }\n",
        "        elif model_type_for_tuning == 'catboost' and CATBOOST_AVAILABLE:\n",
        "            param_dist = {\n",
        "                f\"{param_prefix}iterations\": [500, 800, 1000, 1500],\n",
        "                f\"{param_prefix}depth\": [4, 6, 8, 10],\n",
        "                f\"{param_prefix}learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
        "            }\n",
        "        elif model_type_for_tuning == 'random_forest':\n",
        "            param_dist = {\n",
        "                f\"{param_prefix}n_estimators\": [200, 500, 800, 1000],\n",
        "                f\"{param_prefix}max_depth\": [None, 10, 15, 20, 25],\n",
        "                f\"{param_prefix}min_samples_split\": [2, 5, 10],\n",
        "                f\"{param_prefix}min_samples_leaf\": [1, 2, 4],\n",
        "                f\"{param_prefix}max_features\": [\"sqrt\", \"log2\", 0.3]\n",
        "            }\n",
        "        elif model_type_for_tuning == 'gradient_boosting':\n",
        "            param_dist = {\n",
        "                f\"{param_prefix}n_estimators\": [100, 200, 300, 500],\n",
        "                f\"{param_prefix}max_depth\": [3, 5, 7, 9],\n",
        "                f\"{param_prefix}learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
        "                f\"{param_prefix}subsample\": [0.6, 0.8, 1.0],\n",
        "            }\n",
        "        elif model_type_for_tuning == 'extra_trees':\n",
        "            param_dist = {\n",
        "                f\"{param_prefix}n_estimators\": [200, 500, 800, 1000],\n",
        "                f\"{param_prefix}max_depth\": [None, 10, 15, 20, 25],\n",
        "                f\"{param_prefix}min_samples_split\": [2, 5, 10],\n",
        "                f\"{param_prefix}min_samples_leaf\": [1, 2, 4],\n",
        "            }\n",
        "        else:\n",
        "            print(f\"  â„¹ No hyperparameter tuning defined for {model_type_for_tuning}\")\n",
        "            param_dist = None\n",
        "\n",
        "        if param_dist:\n",
        "            # Choose scoring\n",
        "            if is_multi_target:\n",
        "                scoring = 'accuracy'\n",
        "            else:\n",
        "                n_classes = len(le.classes_)\n",
        "                scoring = 'roc_auc_ovr' if n_classes > 2 else 'roc_auc'\n",
        "\n",
        "            # Run search\n",
        "            rnd_search = RandomizedSearchCV(\n",
        "                estimator=model,\n",
        "                param_distributions=param_dist,\n",
        "                n_iter=CONFIG['n_iter_search'],\n",
        "                scoring=scoring,\n",
        "                cv=3,\n",
        "                verbose=1,\n",
        "                random_state=RANDOM_STATE,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "\n",
        "            rnd_search.fit(X_train_pre, y_train_enc)\n",
        "\n",
        "            print(\"\\nâœ“ Best parameters:\")\n",
        "            for param, value in rnd_search.best_params_.items():\n",
        "                print(f\"  {param}: {value}\")\n",
        "            print(f\"\\nBest CV score: {rnd_search.best_score_:.4f}\")\n",
        "\n",
        "            tuned_model = rnd_search.best_estimator_\n",
        "\n",
        "            # Evaluate tuned model\n",
        "            y_val_pred_tuned = tuned_model.predict(X_val_pre)\n",
        "\n",
        "            if not is_multi_target:\n",
        "                try:\n",
        "                    y_val_proba_tuned = tuned_model.predict_proba(X_val_pre)\n",
        "                    loss_val_tuned = log_loss(y_val_enc, y_val_proba_tuned)\n",
        "                    acc_val_tuned = accuracy_score(y_val_enc, y_val_pred_tuned)\n",
        "\n",
        "                    print(f\"\\nðŸ“Š Tuned Model - Validation Metrics:\")\n",
        "                    print(f\"  Log Loss: {loss_val_tuned:.4f}\")\n",
        "                    print(f\"  Accuracy: {acc_val_tuned:.4f}\")\n",
        "\n",
        "                    if loss_val_tuned < loss_val:\n",
        "                        print(\"  âœ“ Improvement over baseline!\")\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 14. GENERATE PREDICTIONS\n",
        "# ============================================================================\n",
        "\n",
        "print_section(\"GENERATING PREDICTIONS\")\n",
        "\n",
        "final_model = tuned_model if tuned_model is not None else model\n",
        "print(f\"\\nâœ“ Using {'TUNED' if tuned_model else 'BASELINE'} model\")\n",
        "\n",
        "# Determine submission format\n",
        "if CONFIG['submission_type'] == 'probabilities':\n",
        "    print(\"âœ“ Generating probability predictions (for Log Loss)\")\n",
        "\n",
        "    if is_multi_target:\n",
        "        # Multi-target probabilities not commonly used, generate classes\n",
        "        print(\"  â„¹ Multi-target with probabilities not standard, using class predictions\")\n",
        "        test_pred = final_model.predict(test_data_pre)\n",
        "\n",
        "        submission_df = pd.DataFrame({CONFIG['id_col']: test_ids})\n",
        "        for idx, target_col in enumerate(target_cols):\n",
        "            le_temp = label_encoders[target_col]\n",
        "            submission_df[target_col] = le_temp.inverse_transform(test_pred[:, idx])\n",
        "    else:\n",
        "        # Generate probabilities for each class\n",
        "        test_proba = final_model.predict_proba(test_data_pre)\n",
        "\n",
        "        # Create submission DataFrame\n",
        "        if test_ids is not None:\n",
        "            submission_df = pd.DataFrame({CONFIG['id_col']: test_ids})\n",
        "        else:\n",
        "            submission_df = pd.DataFrame()\n",
        "\n",
        "        # Determine column order from sample submission if available\n",
        "        if sample_submission is not None:\n",
        "            # Get probability column names from sample submission (exclude ID column)\n",
        "            expected_columns = [col for col in sample_submission.columns if col != CONFIG['id_col']]\n",
        "\n",
        "            print(f\"\\n  Using column order from sample submission:\")\n",
        "            print(f\"  Expected columns: {expected_columns}\")\n",
        "\n",
        "            # Use the exact columns from sample submission\n",
        "            class_to_idx = {class_name: idx for idx, class_name in enumerate(le.classes_)}\n",
        "\n",
        "            # Create variations to handle prefixes\n",
        "            class_name_variations = {}\n",
        "            for class_name in le.classes_:\n",
        "                class_name_variations[class_name] = class_name\n",
        "                for prefix in ['Status_', 'status_', 'TARGET_', 'target_', 'Class_', 'class_']:\n",
        "                    if class_name.startswith(prefix):\n",
        "                        clean_name = class_name[len(prefix):]\n",
        "                        class_name_variations[clean_name] = class_name\n",
        "                    prefixed = prefix + class_name\n",
        "                    class_name_variations[prefixed] = class_name\n",
        "\n",
        "            # Add columns in exact order from sample submission\n",
        "            columns_added = 0\n",
        "            for col_name in expected_columns:\n",
        "                matched_class = None\n",
        "\n",
        "                if col_name in class_to_idx:\n",
        "                    matched_class = col_name\n",
        "                elif col_name in class_name_variations:\n",
        "                    matched_class = class_name_variations[col_name]\n",
        "                else:\n",
        "                    for prefix in ['Status_', 'status_', 'TARGET_', 'target_', 'Class_', 'class_']:\n",
        "                        if col_name.startswith(prefix):\n",
        "                            potential_match = col_name[len(prefix):]\n",
        "                            if potential_match in class_to_idx:\n",
        "                                matched_class = potential_match\n",
        "                                break\n",
        "\n",
        "                    if matched_class is None:\n",
        "                        for class_name in le.classes_:\n",
        "                            if col_name.endswith(class_name):\n",
        "                                matched_class = class_name\n",
        "                                break\n",
        "\n",
        "                if matched_class and matched_class in class_to_idx:\n",
        "                    idx = class_to_idx[matched_class]\n",
        "                    submission_df[col_name] = test_proba[:, idx]\n",
        "                    columns_added += 1\n",
        "                else:\n",
        "                    print(f\"  âš  Warning: Column '{col_name}' could not be mapped\")\n",
        "                    submission_df[col_name] = 0.0\n",
        "\n",
        "            print(f\"  âœ“ Mapped {columns_added}/{len(expected_columns)} columns from sample submission\")\n",
        "\n",
        "        else:\n",
        "            # No sample submission - use prefix from config\n",
        "            print(f\"\\n  No sample submission - using config settings\")\n",
        "\n",
        "            prefix = CONFIG.get('submission_column_prefix', '')\n",
        "            if prefix:\n",
        "                print(f\"  Adding prefix '{prefix}' to column names\")\n",
        "\n",
        "            # Sort class names to ensure proper order (Q1, Q2, ..., Q10)\n",
        "            classes_sorted = sorted(le.classes_, key=lambda x: (\n",
        "                int(''.join(filter(str.isdigit, str(x)))) if any(c.isdigit() for c in str(x)) else 0,\n",
        "                str(x)\n",
        "            ))\n",
        "\n",
        "            # Create mapping from sorted classes to probability indices\n",
        "            class_to_idx = {class_name: idx for idx, class_name in enumerate(le.classes_)}\n",
        "\n",
        "            for class_name in classes_sorted:\n",
        "                idx = class_to_idx[class_name]\n",
        "                # Add prefix if specified\n",
        "                column_name = f\"{prefix}{class_name}\" if prefix else class_name\n",
        "                submission_df[column_name] = test_proba[:, idx]\n",
        "\n",
        "        print(f\"\\n  Generated probabilities for {len(le.classes_)} classes\")\n",
        "        print(f\"  Final column order: {list(submission_df.columns)}\")\n",
        "\n",
        "else:  # 'classes'\n",
        "    print(\"âœ“ Generating class predictions\")\n",
        "\n",
        "    test_pred = final_model.predict(test_data_pre)\n",
        "\n",
        "    if is_multi_target:\n",
        "        submission_df = pd.DataFrame({CONFIG['id_col']: test_ids})\n",
        "        for idx, target_col in enumerate(target_cols):\n",
        "            le_temp = label_encoders[target_col]\n",
        "            submission_df[target_col] = le_temp.inverse_transform(test_pred[:, idx])\n",
        "    else:\n",
        "        test_pred_decoded = le.inverse_transform(test_pred)\n",
        "\n",
        "        if test_ids is not None:\n",
        "            submission_df = pd.DataFrame({\n",
        "                CONFIG['id_col']: test_ids,\n",
        "                target_cols[0]: test_pred_decoded\n",
        "            })\n",
        "        else:\n",
        "            submission_df = pd.DataFrame({target_cols[0]: test_pred_decoded})\n",
        "\n",
        "# Save submission\n",
        "submission_df.to_csv(CONFIG['output_file'], index=False)\n",
        "print(f\"\\nâœ“ Submission saved to '{CONFIG['output_file']}'\")\n",
        "\n",
        "# Verify format matches sample submission\n",
        "if sample_submission is not None:\n",
        "    print(\"\\n\" + \"-\"*80)\n",
        "    print(\"FORMAT VERIFICATION\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    # Check column match\n",
        "    expected_cols = list(sample_submission.columns)\n",
        "    actual_cols = list(submission_df.columns)\n",
        "\n",
        "    if expected_cols == actual_cols:\n",
        "        print(\"âœ… Column names and order MATCH sample submission perfectly!\")\n",
        "    else:\n",
        "        print(\"âš  Column differences detected:\")\n",
        "        print(f\"  Expected: {expected_cols}\")\n",
        "        print(f\"  Actual:   {actual_cols}\")\n",
        "\n",
        "        missing = set(expected_cols) - set(actual_cols)\n",
        "        extra = set(actual_cols) - set(expected_cols)\n",
        "        if missing:\n",
        "            print(f\"  Missing columns: {missing}\")\n",
        "        if extra:\n",
        "            print(f\"  Extra columns: {extra}\")\n",
        "\n",
        "    # Check shape\n",
        "    if len(submission_df) == len(sample_submission):\n",
        "        print(f\"âœ… Row count matches: {len(submission_df)} rows\")\n",
        "    else:\n",
        "        print(f\"âš  Row count mismatch:\")\n",
        "        print(f\"  Expected: {len(sample_submission)} rows\")\n",
        "        print(f\"  Actual:   {len(submission_df)} rows\")\n",
        "\n",
        "# Display statistics\n",
        "print(\"\\n\" + \"-\"*80)\n",
        "print(\"SUBMISSION SUMMARY\")\n",
        "print(\"-\"*80)\n",
        "print(f\"Total rows: {len(submission_df)}\")\n",
        "print(f\"Columns: {list(submission_df.columns)}\")\n",
        "\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "print(submission_df.head(10))\n",
        "\n",
        "if CONFIG['submission_type'] == 'probabilities' and not is_multi_target:\n",
        "    # Verify probabilities sum to 1\n",
        "    prob_cols = [c for c in submission_df.columns if c != CONFIG['id_col']]\n",
        "    prob_sum = submission_df[prob_cols].sum(axis=1)\n",
        "    print(f\"\\nProbability verification:\")\n",
        "    print(f\"  Min sum: {prob_sum.min():.6f}\")\n",
        "    print(f\"  Max sum: {prob_sum.max():.6f}\")\n",
        "    print(f\"  All sums â‰ˆ 1.0: {np.allclose(prob_sum, 1.0)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"âœ… PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nðŸ’¡ Model Performance Tips:\")\n",
        "print(f\"  - Current model: {CONFIG['model_type']}\")\n",
        "if CONFIG['model_type'] not in ['voting_ensemble', 'stacking_ensemble']:\n",
        "    print(f\"  - Try ensemble methods for better accuracy:\")\n",
        "    print(f\"    â€¢ 'voting_ensemble': Combines multiple models by voting\")\n",
        "    print(f\"    â€¢ 'stacking_ensemble': Uses meta-model to combine predictions\")\n",
        "print(f\"  - Best models for most datasets:\")\n",
        "print(f\"    1. XGBoost (fast, accurate, handles missing values)\")\n",
        "print(f\"    2. LightGBM (very fast, great for large datasets)\")\n",
        "print(f\"    3. CatBoost (excellent for categorical features)\")\n",
        "print(f\"    4. Stacking Ensemble (highest accuracy, slower)\")\n",
        "print(f\"\\nðŸ’¡ Configuration Tips:\")\n",
        "print(f\"  - For Log Loss competitions: submission_type='probabilities'\")\n",
        "print(f\"  - Enable hyperparameter tuning: do_hyperparam_tuning=True\")\n",
        "print(f\"  - Use sample_submission.csv for exact format matching\")\n",
        "print(f\"  - Increase n_estimators (1000-2000) for better accuracy\")"
      ]
    }
  ]
}